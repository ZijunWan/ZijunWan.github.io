<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Frank Wan's Blog - 世界上只有一种真正的英雄主义，就是认清生活的真相后并依然热爱它</title><meta name="keywords" content="Neural Network, Computer Science"><meta name="author" content="Zijun Wan"><meta name="copyright" content="Zijun Wan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Stay Hungry, Stay Foolish">
<meta property="og:type" content="website">
<meta property="og:title" content="Frank Wan&#39;s Blog">
<meta property="og:url" content="http://frankmartinem.github.io/page/3/index.html">
<meta property="og:site_name" content="Frank Wan&#39;s Blog">
<meta property="og:description" content="Stay Hungry, Stay Foolish">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://frankmartinem.github.io/img/avatar.jpg">
<meta property="article:author" content="Zijun Wan">
<meta property="article:tag" content="Neural Network, Computer Science">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://frankmartinem.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://frankmartinem.github.io/page/3/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Zijun Wan","link":"链接: ","source":"来源: Frank Wan's Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Frank Wan\'s Blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-01-23 20:17:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.1">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Frank Wan's Blog" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">39</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/cover/1.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Frank Wan's Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Frank Wan's Blog</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/frankmartinem" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:frankmartinet@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://twitter.com/wanzijun95" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a><a class="social-icon" href="https://www.facebook.com/profile.php?id=100075929412180" target="_blank" title="Facebook"><i class="fab fa-facebook"></i></a><a class="social-icon" href="https://www.douban.com/people/122349831/" target="_blank" title="Douban"><i class="fab fa-douban"></i></a><a class="social-icon" href="https://blog.csdn.net/frankgoogle" target="_blank" title="CSDN"><i class="fab fa-csdn"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2020/04/17/Linear-Square-Method/" title="Linear Square Method"><img class="post_bg" src="/img/cover/11.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linear Square Method"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/17/Linear-Square-Method/" title="Linear Square Method">Linear Square Method</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-16T23:09:41.000Z" title="发表于 2020-04-17 01:09:41">2020-04-17</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/ALGORITHMS/">ALGORITHMS</a></span></div><div class="content"> 最小二乘法
这几天看书的时候突然注意到了这个经典的优化方法，于是重新推导了一遍，为以后应用做参考。
 背景
最小二乘法应该是我接触的最早的优化方法，也是求解线性回归的一种方法。线性回归的主要作用是用拟合的方式，求解两组变量之间的线性关系（当然也可以不是线性的，那就是另外的回归方法了）。也就是把一个系统的输出写成输入的线性组合的形式。而这组线性关系的参数求解方法，就是最小二乘法。
我们从最简单的线性回归开始，即输入和输出都是1维的。此时，最小二乘法也是最简单的。
假设有输入信号x={x0,x1,...,xt}x = \{x_0, x_1, ..., x_t\}x={x​0​​,x​1​​,...,x​t​​}，同时输出信号为y={y0,y1,...,yt}y = \{y_0, y_1, ..., y_t\}y={y​0​​,y​1​​,...,y​t​​}，我们假设输入信号xxx和输出信号yyy之间的关系可以写成如下形式：
y_{pre} = ax+b \tag{1}

我们需要求解最优的aaa和bbb，这里最优的含义就是，预测的最准确，也就是预测值和真实值的误差最小，即：
arg\, ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/04/13/Wiener-Filter/" title="Wiener-Filter"><img class="post_bg" src="/img/cover/26.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Wiener-Filter"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/13/Wiener-Filter/" title="Wiener-Filter">Wiener-Filter</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-13T15:32:08.000Z" title="发表于 2020-04-13 17:32:08">2020-04-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/MACHINE-LEARNING/">MACHINE LEARNING</a></span></div><div class="content"> Wiener Filter
因为最近看文章接触了维纳滤波，所以这里写一下Weiner Filter的一些简单理解和推导。
 基本定义
维纳滤波是一种在含噪声的时序信号把信号提取出来的滤波器，其基本框图如下：

简单的维纳滤波其实就是通过一个FIR滤波器，去除噪声的过程。在这里，hhh的作用也可以理解为： 通过训练集的数据对信号和噪声的建模，然后通过前几个点的信息，预测当前时刻的噪声信号所占的比例，然后去除掉，剩下的就是预测的时序信号了。维纳滤波作为一种使用很广泛的滤波器，其变化的形式也有很多种，可以是单输入输出的，也可以是多输入输出的。hhh所表示的变换也可以写成非线性；hhh可以是有限长的FIR滤波器，也可以是无限长的IIR滤波器。要取决于当前你所解决的问题。但是维纳滤波的基本思想还是一致的。通过滤波（矩阵或者其他模型的形式）来从信号和噪声的混合中提取信号。所以维纳滤波的核心，就是计算这个滤波器（矩阵hhh或者模型的参数）。也就是解Wiener-Hopf方程。
本文用比较简单的单输入输出，且只考虑有限长滤波（即认为当前时刻的信号只和前有限个时间点的信号相关）。
 公式推导
首先，对 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2020/03/20/python-note/" title="python_note"><img class="post_bg" src="/img/cover/9.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="python_note"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/03/20/python-note/" title="python_note">python_note</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-03-20T14:00:48.000Z" title="发表于 2020-03-20 15:00:48">2020-03-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LANGUAGE/">LANGUAGE</a></span></div><div class="content"> Python
 Basic Knowledge


python中新建一个变量并赋值，在计算机中是怎么处理的
x = 1
例如上述代码，计算机首先是开辟一块内存 ，如果是C++，Java等静态语言，那么会根据变量类型指定内存大小。如果是python等动态语言，则智能开辟内存大小，在内存中写入这一数据；但是计算机到目前为止，还不能将x和该值绑定，所以计算机中还会开辟一块内存，名字为x，然后将这一内存指向刚才开辟的内存地址。


python中没有指针的概念，例如下面的代码
x = 1
y = x
x = 2
在python中，这一过程是这样的：

开辟内存，存入1，开辟内存，存入x，并将x指向刚才开辟的存入1的内存
开辟内存，存入y，并将y也指向x指向的那块内存
开辟内存，存入2，并将x指向新开的地址

如果是在C++, Java等有指针概念的语言中，第二步应该是这样的，开辟新的内存，将x指向的地址的值复制一份存入新地址，开辟内存，存入y，并指向新地址


python循环
python中的循环有如下2种方式：


for循环
python中的for循环的写法是for x in y,  ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/02/23/Linear-Algebra/" title="Linear Algebra"><img class="post_bg" src="/img/cover/9.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linear Algebra"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/23/Linear-Algebra/" title="Linear Algebra">Linear Algebra</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-23T12:32:52.000Z" title="发表于 2020-02-23 13:32:52">2020-02-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/ALGORITHMS/">ALGORITHMS</a></span></div><div class="content"> 线性代数
本文主要记录学习过程中遇到的线性代数的基本概念以及公式
 Basic Concept
 行列式的计算
矩阵的行列式等于矩阵中任意一行的值
</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2020/02/06/Gradient-Descent-Method/" title="Gradient Descent Method"><img class="post_bg" src="/img/cover/8.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Gradient Descent Method"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/06/Gradient-Descent-Method/" title="Gradient Descent Method">Gradient Descent Method</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-06T14:25:52.000Z" title="发表于 2020-02-06 15:25:52">2020-02-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/DEEP-LEARNING/">DEEP LEARNING</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/DEEP-LEARNING/ALGORITHMS/">ALGORITHMS</a></span></div><div class="content"> 梯度下降法
这篇Blog的主要内容是关于梯度下降法的一些理解，以及相关的公式推导。梯度下降法很早之前就接触过，但是因为长时间不用，所以理解上也有了一些欠缺，今天看了一些参考文献，写一下自己的一些理解。便于以后帮助自己回忆。
 Artificial Neural Network
关于人工神经网络，这是目前使用最广泛的一类算法了。神经网络和其他的算法相比较，计算更加直接。不需要去推导公式，去计算两者的关系，直接通过网络的方式连接，然后用大量的数据训练，没有关系的连接权重逐渐变弱，有关系的权重逐渐变强。如果把输入和输出的函数关系写出来，会发现是一个很复杂的非线性公式。也正是因为这一点，神经网络的拟合程度比普通的线性，非线性算法都要好。
 Gradient Descent
对于用梯度下降法训练神经网络，我之前一直没有弄明白的点是为什么梯度的方向就是函数增加最快的方向， 我理解梯度方向是变化最快的方向，但是一直不理解为什么是增加的。今天看了一些参考文献，理解了一点。
对于神经网络，我们会有训练集的数据{x0,y0}\{x_0, y_0\}{x​0​​,y​0​​}，xxx和yyy之间有函数关系 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/01/21/Brain-Structure-Conference/" title="Brain Structure Conference"><img class="post_bg" src="/img/cover/22.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Brain Structure Conference"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/01/21/Brain-Structure-Conference/" title="Brain Structure Conference">Brain Structure Conference</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-01-21T13:11:55.000Z" title="发表于 2020-01-21 14:11:55">2020-01-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/COURSE/">COURSE</a></span></div><div class="content"> 介观脑连接研讨会

 Focused Questions

大脑神经回路与功能的关系
大脑神经连接的建模与计算

 Muming Poo


mapping and understanding
genetic programs and neural circuits, subtypes and substates



Jun Yan

single neuron projectome
projection subtypes, CT
brain  orders and projectome classification, 观察轴突分叉点的夹角



 Florian Engert

不同类型的神经元组成不同的神经回路，回路之间互相影响，各有各的作用。

 JiuLin Du

神经元分类， vglut2a, vglut2b(excitory), GABA(jinhibotiry)等

神经信号的传递有兴奋和抑制之分，不同的神经递质对应了不同的神经信号的gate


gene expression
信息传导通路

 Hongkui Zheng


multi-level approac ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2020/01/21/Unscented-Kalman-Filter/" title="Unscented Kalman Filter"><img class="post_bg" src="/img/cover/17.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Unscented Kalman Filter"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/01/21/Unscented-Kalman-Filter/" title="Unscented Kalman Filter">Unscented Kalman Filter</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-01-21T13:10:25.000Z" title="发表于 2020-01-21 14:10:25">2020-01-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/MACHINE-LEARNING/">MACHINE LEARNING</a></span></div><div class="content"> Unscented Kalman Filter
最近读了一篇文献，里面用到了无迹卡尔曼滤波(Unscented Kalman Filter)。这里写一下我对这种方法的理解。卡尔曼滤波的理解部分可以参考
 我的一点点理解
无迹卡尔曼滤波是对卡尔曼滤波的一种改进。这种改进主要是针对非线性的信号。因为在卡尔曼滤波中，预测模型以及测量空间对应的转换矩阵都是都是线性转换。但是在面对非线性信号时，会出现无法拟合的情况。所以就有了无极卡尔曼滤波。这种方法的主要改进在于，不再用线性的模型去计算预测模型以及转换矩阵，而是通过采样和计算均值方法的方式，去估计样本的方差和均值。
 计算过程
无迹卡尔曼滤波的计算方式和卡尔曼滤波比较类似，只是讲线性转换模型换成了采样的方式。具体的原理推导比较复杂，所以这里只写一下无迹卡尔曼滤波的计算过程：
无迹卡尔曼的计算步骤和卡尔曼滤波基本是一致的，只是对其中的一些步骤进行了修改，首先，我们看一下Kalman Filter的计算过程：


建立编码模型和转换模型， 假设观测变量是zzz， 测量变量是xxx， 那么首先我们假设：

当前时刻的测量变量是可以根据上一时刻的测量 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/01/21/Unity/" title="Unity"><img class="post_bg" src="/img/cover/23.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Unity"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/01/21/Unity/" title="Unity">Unity</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-01-21T13:10:10.000Z" title="发表于 2020-01-21 14:10:10">2020-01-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/DEVELOPMENT/">DEVELOPMENT</a></span></div><div class="content"> Unity相关概念


ConfigurableJoint


OnEnable()函数在gameObject.setActive(true)时触发，优先于Start()，但是和Awake()函数的先后顺序不确定；OnDisable()函数在gameObject.setActive(false)时触发


Lerp()


计算两个点之间的插值，函数如下：
Lerp(Vector3 a, Vector3 b, float t);
计算公式如下：
(b−a)∗t(b - a) * t 
(b−a)∗t




Mathf.Approximately()


判断两个浮点数是否十分接近，使用方法如下：
Mathf.Approximately(float a, float b);
返回值为bool




Quaternion类

Quaternion属于四元数，包括x, y, z, w四个分量，和欧拉角一样，是3D图形中常用的坐标变换表示方法之一，对于插值，平滑以及数据存储，都有较大的优势（相较于传统的矩阵表示方法）




</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2020/01/21/Two-Types-of-Variance/" title="Two Types of Variance"><img class="post_bg" src="/img/cover/27.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Two Types of Variance"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/01/21/Two-Types-of-Variance/" title="Two Types of Variance">Two Types of Variance</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-01-21T13:09:44.000Z" title="发表于 2020-01-21 14:09:44">2020-01-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/ALGORITHMS/">ALGORITHMS</a></span></div><div class="content"> 样本方差和统计方差
我们知道，统计学上方差的计算公式如下：
σ2=∑i=1n(xi−μ)n\sigma^2=\frac{\sum_{i=1}^{n}(x_i-\mu)}{n}
σ​2​​=​n​​∑​i=1​n​​(x​i​​−μ)​​
这是统计学中方差的定义，已知条件有总体的均值μ\muμ，以及总体个数nnn，公式的另一种写法为： $$\sigma2=E[(x-\mu)2]=\sum{(x-\mu)^2}p(x)$$
其中p(x)p(x)p(x)是xxx出现的概率，所以这个公式只对于离散变量有效。 那么，如果总体量很大，不能做到全部采样，那么就需要用样本来估计总体，假设从总体为NNN的总数中抽取nnn个样本，其中(N&gt;&gt;n)(N&gt;&gt;n)(N&gt;&gt;n)，采样值为x1,x2,...,xnx_1,x_2,...,x_nx​1​​,x​2​​,...,x​n​​ 样本均值为：
x¯=∑i=1nxin\bar{x}=\frac{\sum_{i=1}^{n}{x_i}}{n}
​x​¯​​=​n​​∑​i=1​n​​x​i​​​​
样本的方差为：
S2=∑i= ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/01/21/Population-Vector-Algorithm/" title="Population Vector Algorithm"><img class="post_bg" src="/img/cover/25.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Population Vector Algorithm"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/01/21/Population-Vector-Algorithm/" title="Population Vector Algorithm">Population Vector Algorithm</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-01-21T13:09:04.000Z" title="发表于 2020-01-21 14:09:04">2020-01-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/ALGORITHMS/">ALGORITHMS</a></span></div><div class="content"> PVA(Population Vector Algorithm)
 算法推导：


信号预处理 这里的算法推导主要针对神经元集群解码，因为PVA的主要应用还是在神经元解码中 首先，采集到的spike信号是以发放次数的方式存储的，这里需要先转换成发放率的形式，即： $$fr[n]=\frac{spk[n]}{\Delta t} \tag{1}$$


其中，fr[n]fr[n]fr[n]表示nnn时刻神经元的发放率，Δt\Delta tΔt表示一个bin的长度，通常的取值为20ms，30ms，50ms，1000ms等。spk[n]spk[n]spk[n]表示神经元在第nnn个bin中发放的次数。 然后，对发放率做一个FIR滤波，主要目的是平滑发放率曲线，计算公式如下：
s[n]=\sum_{i=1}^{W-1}{fr[n-i]h[i]} \tag{2}

其中，h[i]h[i]h[i]表示滤波器的卷积函数，可以根据需求选取，WWW表示滤波器的阶数，可以根据实际需要选择。
PVA算法原理 PVA算法的提出，主要是根据实验中观察到的现象。在猴子将手臂移动向不同的方向时，不同的神经元发放的率 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2020/01/21/Hidden-Markov-Model/" title="Hidden Markov Model"><img class="post_bg" src="/img/cover/11.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hidden Markov Model"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/01/21/Hidden-Markov-Model/" title="Hidden Markov Model">Hidden Markov Model</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-01-21T13:08:45.000Z" title="发表于 2020-01-21 14:08:45">2020-01-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/MACHINE-LEARNING/">MACHINE LEARNING</a></span></div><div class="content"> Hidden Markov Model
 背景
隐马尔可夫模型(Hidden Markov Model)是一种常用的统计模型。应用也比较广泛，在时序问题，以及语音识别等问题上有广泛的应用。下面简单介绍一下隐马尔可夫模型。
隐马尔可夫模型是在马尔可夫过程的基础上，加入了隐含状态后的一种结构。这里首先介绍一下什么是马尔可夫过程(Markov Process)
在一个随机过程中，有一个状态变量III，其下一时刻的状态之和之前的状态有关。例如布朗运动，粒子的下一时刻状态之和之前时刻的状态有关。而III变化的过程，也就是马尔科夫链。这个约束，也就是马尔可夫假设。

在马尔可夫过程中，模型还是很复杂，我们还可以加约束来让模型变得简单一点。我们可以假设，状态变量III的下一时刻状态只和上一时刻的状态有关。这样就得到了齐次马尔可夫模型。即：
p(It∣It−1,It−2,...,I0)=p(It∣It−1),t=1,2,...,Tp(I_t|I_{t-1}, I_{t-2}, ..., I_{0}) = p(I_t|I_{t-1}), t=1, 2, ..., T
p(I​t​​∣I​t−1​​,I ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/01/21/Principle-Component-Analysis/" title="Principle Component Analysis"><img class="post_bg" src="/img/cover/26.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Principle Component Analysis"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/01/21/Principle-Component-Analysis/" title="Principle Component Analysis">Principle Component Analysis</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-01-21T13:08:27.000Z" title="发表于 2020-01-21 14:08:27">2020-01-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/MACHINE-LEARNING/">MACHINE LEARNING</a></span></div><div class="content"> 主成分分析
写一下算法的基本原理和实现
 PCA(Principle Component Analysis)
PCA是最常见的一种降维算法，其核心思想是数据从高维到低维的投影，使其方差最大化。这个也很好理解，比如，这里我们假设有3组数据a1,a2,a3a_1,a_2,a_3a​1​​,a​2​​,a​3​​，然后第1组的值可以用第2组数据的函数表示，比如a2=2∗a1a_2=2*a_1a​2​​=2∗a​1​​。如果以a1,a2,a3a_1,a_2,a_3a​1​​,a​2​​,a​3​​为坐标画出对应的图像，那么在3维空间中就对应了一个平面，以这个平面的坐标轴为参数，此时看到的就是二维数据，相当于降维了。
插图（参考文献）

参考文献：
假设我们有mmm组nnn维数据，希望能降维到kkk维(k&lt;dk&lt;dk&lt;d)，PCA的计算过程如下：
数据零均值化
求协方差矩阵
求协方差矩阵对应的特征值和特征向量
将特征向量按特征值大小取前kkk行从上向下组成矩阵
将得到的矩阵乘以XXX就能得到降维后的数据
这里数据零均值化主要是为了方便后面的计算（测试一下不做这一步有什么问题） ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/#content-inner">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/#content-inner">4</a><a class="extend next" rel="next" href="/page/4/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Zijun Wan</div><div class="author-info__description">Stay Hungry, Stay Foolish</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">39</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/FrankMartinem"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/frankmartinem" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:frankmartinet@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://twitter.com/wanzijun95" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a><a class="social-icon" href="https://www.facebook.com/profile.php?id=100075929412180" target="_blank" title="Facebook"><i class="fab fa-facebook"></i></a><a class="social-icon" href="https://www.douban.com/people/122349831/" target="_blank" title="Douban"><i class="fab fa-douban"></i></a><a class="social-icon" href="https://blog.csdn.net/frankgoogle" target="_blank" title="CSDN"><i class="fab fa-csdn"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">Il n'ya qu'un héroïsme au monde, c'est de voir le monde tel qu'il est et de l'aimer</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/01/18/Mel-Frequency-Cepstral-CoefficientsMel-Frequency-Cepstral-Coefficients/" title="Mel Frequency Cepstral Coefficients"><img src="/img/cover/15.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Mel Frequency Cepstral Coefficients"/></a><div class="content"><a class="title" href="/2022/01/18/Mel-Frequency-Cepstral-CoefficientsMel-Frequency-Cepstral-Coefficients/" title="Mel Frequency Cepstral Coefficients">Mel Frequency Cepstral Coefficients</a><time datetime="2022-01-18T09:27:41.000Z" title="发表于 2022-01-18 10:27:41">2022-01-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/13/tensorboard-ssh/" title="tensorboard ssh"><img src="/img/cover/22.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="tensorboard ssh"/></a><div class="content"><a class="title" href="/2022/01/13/tensorboard-ssh/" title="tensorboard ssh">tensorboard ssh</a><time datetime="2022-01-13T15:30:51.000Z" title="发表于 2022-01-13 16:30:51">2022-01-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/10/self-attention/" title="self-attention"><img src="/img/cover/27.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="self-attention"/></a><div class="content"><a class="title" href="/2022/01/10/self-attention/" title="self-attention">self-attention</a><time datetime="2022-01-10T21:45:47.000Z" title="发表于 2022-01-10 22:45:47">2022-01-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/07/tmux-command/" title="tmux command"><img src="/img/cover/13.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="tmux command"/></a><div class="content"><a class="title" href="/2022/01/07/tmux-command/" title="tmux command">tmux command</a><time datetime="2022-01-07T09:24:53.000Z" title="发表于 2022-01-07 10:24:53">2022-01-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/25/Conditional-Generative-Adversarial-Nets/" title="Conditional Generative Adversarial Nets"><img src="/img/cover/21.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Conditional Generative Adversarial Nets"/></a><div class="content"><a class="title" href="/2021/12/25/Conditional-Generative-Adversarial-Nets/" title="Conditional Generative Adversarial Nets">Conditional Generative Adversarial Nets</a><time datetime="2021-12-25T20:46:40.000Z" title="发表于 2021-12-25 21:46:40">2021-12-25</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/ALGORITHMS/"><span class="card-category-list-name">ALGORITHMS</span><span class="card-category-list-count">5</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/COURSE/"><span class="card-category-list-name">COURSE</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DEEP-LEARNING/"><span class="card-category-list-name">DEEP LEARNING</span><span class="card-category-list-count">4</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DEEP-LEARNING/ALGORITHMS/"><span class="card-category-list-name">ALGORITHMS</span><span class="card-category-list-count">1</span></a></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DEEPLEARNING/"><span class="card-category-list-name">DEEPLEARNING</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DEVELOPMENT/"><span class="card-category-list-name">DEVELOPMENT</span><span class="card-category-list-count">14</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LANGUAGE/"><span class="card-category-list-name">LANGUAGE</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/MACHINE-LEARNING/"><span class="card-category-list-name">MACHINE LEARNING</span><span class="card-category-list-count">7</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Audio/" style="font-size: 1.1em; color: #999">Audio</a> <a href="/tags/attention/" style="font-size: 1.1em; color: #999">attention</a> <a href="/tags/cgan/" style="font-size: 1.1em; color: #999">cgan</a> <a href="/tags/compile/" style="font-size: 1.2em; color: #999da3">compile</a> <a href="/tags/conference/" style="font-size: 1.1em; color: #999">conference</a> <a href="/tags/configuration/" style="font-size: 1.1em; color: #999">configuration</a> <a href="/tags/cpp/" style="font-size: 1.2em; color: #999da3">cpp</a> <a href="/tags/gan/" style="font-size: 1.1em; color: #999">gan</a> <a href="/tags/git/" style="font-size: 1.1em; color: #999">git</a> <a href="/tags/gradient-descent/" style="font-size: 1.1em; color: #999">gradient descent</a> <a href="/tags/hmm/" style="font-size: 1.1em; color: #999">hmm</a> <a href="/tags/kalman/" style="font-size: 1.1em; color: #999">kalman</a> <a href="/tags/latex/" style="font-size: 1.1em; color: #999">latex</a> <a href="/tags/linear-algebra/" style="font-size: 1.1em; color: #999">linear algebra</a> <a href="/tags/linear-regression/" style="font-size: 1.1em; color: #999">linear regression</a> <a href="/tags/linux/" style="font-size: 1.4em; color: #99a5b6">linux</a> <a href="/tags/notes/" style="font-size: 1.5em; color: #99a9bf">notes</a> <a href="/tags/ole/" style="font-size: 1.1em; color: #999">ole</a> <a href="/tags/pca/" style="font-size: 1.1em; color: #999">pca</a> <a href="/tags/powershell/" style="font-size: 1.1em; color: #999">powershell</a> <a href="/tags/probability/" style="font-size: 1.2em; color: #999da3">probability</a> <a href="/tags/pva/" style="font-size: 1.1em; color: #999">pva</a> <a href="/tags/python/" style="font-size: 1.1em; color: #999">python</a> <a href="/tags/pytorch/" style="font-size: 1.1em; color: #999">pytorch</a> <a href="/tags/qt/" style="font-size: 1.1em; color: #999">qt</a> <a href="/tags/ssh/" style="font-size: 1.3em; color: #99a1ac">ssh</a> <a href="/tags/ukf/" style="font-size: 1.2em; color: #999da3">ukf</a> <a href="/tags/unity/" style="font-size: 1.1em; color: #999">unity</a> <a href="/tags/vpn/" style="font-size: 1.2em; color: #999da3">vpn</a> <a href="/tags/wiener/" style="font-size: 1.1em; color: #999">wiener</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/01/"><span class="card-archive-list-date">一月 2022</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/12/"><span class="card-archive-list-date">十二月 2021</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/09/"><span class="card-archive-list-date">九月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/08/"><span class="card-archive-list-date">八月 2021</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/07/"><span class="card-archive-list-date">七月 2021</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/06/"><span class="card-archive-list-date">六月 2021</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/05/"><span class="card-archive-list-date">五月 2021</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/05/"><span class="card-archive-list-date">五月 2020</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">39</div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-01-23T19:17:00.037Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div></div></body></html>