<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>FrankMartinem Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Frank&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Frank&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Stay Hungry, Stay Foolish"><meta property="og:type" content="blog"><meta property="og:title" content="FrankMartinem Blog"><meta property="og:url" content="http://frankmartinem.github.io/"><meta property="og:site_name" content="FrankMartinem Blog"><meta property="og:description" content="Stay Hungry, Stay Foolish"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://frankmartinem.github.io/img/og_image.png"><meta property="article:author" content="Frank"><meta property="article:tag" content="Neural Network, Computer Science"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://frankmartinem.github.io"},"headline":"FrankMartinem Blog","image":["http://frankmartinem.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Frank"},"description":"Stay Hungry, Stay Foolish"}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="FrankMartinem Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" target="_blank" rel="noopener" href="https://github.com/ppoffice/hexo-theme-icarus">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/FrankMartinem"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-05-28T08:50:27.000Z" title="2021/5/28 下午4:50:27">2021-05-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-05-28T13:31:17.781Z" title="2021/5/28 下午9:31:17">2021-05-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Algorithm/">Algorithm</a></span><span class="level-item">10 minutes read (About 1565 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/05/28/Optimal-Linear-Estimation/">Optimal Linear Estimation</a></h1><div class="content"><h1 id="Optimal-Linear-Estimation"><a href="#Optimal-Linear-Estimation" class="headerlink" title="Optimal Linear Estimation"></a>Optimal Linear Estimation</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最优线性估计算法是神经解码中一种比较常用的算法。在算法刚提出来的时候，其解码精度和解码速度都属于较高的水准，因此在脑机接口实验中应用广泛。随着神经网络的兴起以及传统机器学习算法的更新，BCI领域用来解码的算法也越来越多，例如KF，UKF，RNN，CNN等。OLE尽管计算精度不如目前的算法，但是计算量小，反馈迅速。因此目前在线的BCI实验OLE的应用仍然较多。</p>
<h2 id="算法推导"><a href="#算法推导" class="headerlink" title="算法推导"></a>算法推导</h2><p>OLE算法是PVA算法的改进，PVA算法在之前的Blog中有提到，是BCI中应用最早的算法。但是PVA有自己的缺陷，即很依赖数据的质量。这里的质量指的是用于解码的神经元集群的偏好方向分布。如果偏好方向的分布不均匀，朝某个方向的神经元占大多数，那么解码得到的方向就会偏向于这个方向，导致朝其他方向的运动很困难。为了解决这个问题，Chase等人提出了对于PVA算法的改进方法，即OLE算法[1]。<br>OLE算法的核心思想就是利用线性插值的方法，把神经元的偏好方向调整到尽量在各个方向都是均匀分布的。我们假设有2个神经元，偏好方向如图1中红色和蓝色的虚线所示。当朝各个方向运动时，神经元的发放率变化程度会不一样。当朝着神经元偏好方向运动时，神经元会更活跃，朝反方向运动时，会更加被抑制。但是当朝着垂直于偏好方向的方向运动时，神经元的发放率不会有明显变化，此时，解码误差会很大，或者说，很难解码到朝这个方向的运动。<br>为了便于理解这个问题，我们可以用一个更极端的假设，即所有神经元的偏好方向都朝向x轴正方向，那么此时对于y轴的运动，是无法通过神经元解码得到的。PVA的计算公式里，y轴运动的参数$b_1$是0。这里有一个需要理解的概念，即神经元集群的解码，不是取决于神经元的发放率，而是发放率的变化。朝哪个方向运动能有神经元有强烈的发放率变化，那么朝这个方向的运动解码就准确。<br><img src="../img/Optimal-Linear-Estimation-1.png" alt="Bias Preferred Direction"><br>为了解决上述问题，Chase等人提出了OLE算法，具体的计算方法如下：<br>假设神经元的发放率为$r(t)$。神经元的偏好方向矩阵为$B$，当前的运动方向为$d(t)$。那么有：<br>$$r(t) = B * d(t) + \epsilon(t) $$<br>其中$\epsilon(t)$表示$t$时刻的噪声。假设神经元的个数为$N$，那么$r(t) \in R^{Nx1}$。假设解码的维度为$d$，那么$B \in R^{Nx(d+1)}$。这里加1表示常数项。<br>那么，预测的运动方向为：<br>$$d_{pred}(t) = (B’B)^{-1}B’r(t)$$<br>以上就是OLE算法的计算内容。和PVA算法比较，似乎没什么太大的差别。但是思想是不同的。<br>首先，PVA的计算，前提假设就包括了神经元的分布是均匀的。体现在这里，即$B’B=I$，其中$I$表示单位矩阵。那么上述公式可以写为：$d_{pred}(t) = B’r(t)$。即PVA的计算方法，单独计算每个神经元的发放率，然后计算在当前偏好方向的投影，然后求和之后得到预测的运动方向。<br>对于OLE的计算，更加像是先计算了神经元分布的均匀度。然后根据不同方向的运动权重重新分布当前的偏好方向。使得神经元分布更加均匀。即$B’B$这个矩阵的计算值，也就是运动维度的协方差。这里举个例子，假设所有神经元的偏好方向都是x轴正方向，那么$B’B=[[1, 1], [0, 0]]$。 这个时候x轴和y轴的运动都会存在。即我们把神经元的偏好方向从x轴正方向旋转了45度。Chase的文章中的图可以很好的解释这个原理：<br><img src="../img/Optimal-Linear-Estimation-2.png" alt="Optimal Prefered Direction"><br>需要注意的是，$B$矩阵的计算方法和PVA算法是一致的。<br>以上就是OLE算法的计算过程了，OLE的计算方法和PVA很像，但是解决了神经元分布不均匀的问题。这个问题在BCI中很常见，所以OLE相较于PVA，效果一般都是会更好的。还有一种改进版的OLE算法-‘full OLE’。之前介绍的这种是’minimal OLE’。 ‘full OLE’ 相较于’minimal OLE’的区别在于其假设了神经信号中存在了同源或相似的噪声。那么在计算过程中，这种噪声会体现在解码的结果上，导致运动方向产生误差。其改进方法也很简单，只是在预测公式中，加入了所有通道神经元的协方差矩阵，如下：<br>$$d_{pred}(t) = (B’\Sigma B)^{-1}B’r(t)$$<br>这里的$\Sigma$就是协方差矩阵，如果神经信号之间没有相关性，即没有同源噪声的话，$\Sigma = I$。也就是’minial OLE’的计算方法了。</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>后续会附上代码链接</p>
<p>[1]    S. M. Chase, A. B. Schwartz, and R. E. Kass, “Bias, optimal linear estimation, and the differences between open-loop simulation and closed-loop performance of spiking-based brain–computer interface algorithms,” Neural networks, vol. 22, no. 9, pp. 1203-1213, 2009.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-05-03T10:29:42.000Z" title="2021/5/3 下午6:29:42">2021-05-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-05-03T10:37:42.463Z" title="2021/5/3 下午6:37:42">2021-05-03</time></span><span class="level-item"><a class="link-muted" href="/categories/software/">software</a></span><span class="level-item">a minute read (About 158 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/05/03/ZJU%20RVPN%20Initialize%20Failed/">ZJU RVPN initialize failed</a></h1><div class="content"><h2 id="ZJU-RVPN-初始化失败的解决办法"><a href="#ZJU-RVPN-初始化失败的解决办法" class="headerlink" title="ZJU RVPN 初始化失败的解决办法"></a>ZJU RVPN 初始化失败的解决办法</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>在 macOS系统，遇见easyconnect一直提示初始化失败的问题。重新安装后仍旧不能解决问题。后发现是macOS系统开机时禁止启动了两个easyconnect的进程。分别为：</p>
<ol>
<li>com.sangfor.EasyMonitor.plist</li>
<li>com.sangfor.ECAgentProxy.plist<br>禁止后easyconnect无法启动代理，连接校内网络</li>
</ol>
<h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>用软件Tencent Lemon设置开机启动项，在“未知应用“选项中找到对应的进程，打开开机启动项。然后重启电脑，即可解决问题</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-05-16T09:01:22.000Z" title="2020/5/16 下午5:01:22">2020-05-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-13T00:59:38.113Z" title="2021/4/13 上午8:59:38">2021-04-13</time></span><span class="level-item"><a class="link-muted" href="/categories/Lecture/">Lecture</a></span><span class="level-item">a few seconds read (About 61 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/16/Berkeley-CS-61A/">Berkeley-CS-61A</a></h1><div class="content"><h1 id="Berkeley-CS-61C"><a href="#Berkeley-CS-61C" class="headerlink" title="Berkeley CS 61C"></a>Berkeley CS 61C</h1><h2 id="Lecture-1"><a href="#Lecture-1" class="headerlink" title="Lecture-1"></a>Lecture-1</h2><ol>
<li>不是所有的问题都能用计算机解决，也不是所有的问题，用计算机解决更加方便</li>
<li>学会抽象的看待事物，不需要了解其中的详细构造</li>
<li></li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-04-16T17:09:41.000Z" title="2020/4/17 上午1:09:41">2020-04-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-13T01:02:10.124Z" title="2021/4/13 上午9:02:10">2021-04-13</time></span><span class="level-item"><a class="link-muted" href="/categories/Algorithm/">Algorithm</a></span><span class="level-item">6 minutes read (About 933 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/17/Linear-Square-Method/">Linear Square Method</a></h1><div class="content"><h1 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h1><p>这几天看书的时候突然注意到了这个经典的优化方法，于是重新推导了一遍，为以后应用做参考。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最小二乘法应该是我接触的最早的优化方法，也是求解线性回归的一种方法。线性回归的主要作用是用拟合的方式，求解两组变量之间的线性关系（当然也可以不是线性的，那就是另外的回归方法了）。也就是把一个系统的输出写成输入的线性组合的形式。而这组线性关系的参数求解方法，就是最小二乘法。</p>
<p>我们从最简单的线性回归开始，即输入和输出都是1维的。此时，最小二乘法也是最简单的。</p>
<p>假设有输入信号$x = {x_0, x_1, …, x_t}$，同时输出信号为$y = {y_0, y_1, …, y_t}$，我们假设输入信号$x$和输出信号$y$之间的关系可以写成如下形式：</p>
<p>$$y_{pre} = ax+b \tag{1}$$</p>
<p>我们需要求解最优的$a$和$b$，这里最优的含义就是，预测的最准确，也就是预测值和真实值的误差最小，即：</p>
<p>$$arg, min_{a, b}{\sum_{i=0}^{t}{(y_i-ax_i-b)^2}} \tag{2}$$</p>
<p>我们假设误差函数为：</p>
<p>$$err = \sum_{i=0}^{t}{(y_i-ax_i-b)^2} \tag{3}$$</p>
<p>$err$对$a$和$b$分别求偏导：</p>
<p>$$\frac{\partial{err}}{\partial{a}} = \sum_{i=0}^{t}{2(ax_i+b-y_i)*x_i} \tag{4}$$</p>
<p>$$\frac{\partial{err}}{\partial{b}} = \sum_{i=0}^{t}{2(ax_i+b-y_i)} \tag{5}$$</p>
<p>根据极值定理，有$$\frac{\partial{err}}{\partial{a}}=0$$，且$$\frac{\partial{err}}{\partial{b}}=0$$，所以有：</p>
<p>$$\sum_{i=0}^{t}{2(ax_i+b-y_i)} = 0 \tag{6}$$</p>
<p>$$\sum_{i=0}^{t}(y_i - ax_i) = \sum_{i=0}^{t}{b} \tag{7}$$</p>
<p>$$\sum_{i=0}^{t}{y_i} - a * \sum_{i=0}^{t}{x_i} = (t+1)*b \tag{8}$$</p>
<p>$$b = \bar{y} - a\bar{x} \tag{9}$$</p>
<p>其中，$\bar{y}$表示$y$的均值，$\bar{x}$表示$x$的均值。将Eq(9)代入Eq(4)，有：</p>
<p>$$\sum_{i=0}^{t}{2(ax_i+b-y_i)*x_i} = 0 \tag{10}$$</p>
<p>$$\sum_{i=0}^{t}{ax_i^2} + \sum_{i=0}^{t}bx_i = \sum_{i=0}^{t}{y_ix_i} \tag{11}$$</p>
<p>$$a\sum_{i=0}^{t}x_i^2 + \bar{x}(\bar{y}-a\bar{x}) = \sum_{i=0}^{t}{x_iy_i} \tag{12}$$</p>
<p>$$a(\sum_{i=0}^{t}{x_i^2 - \bar{x}^2}) = \sum_{i=0}^{t}{x_iy_i}-\bar{x}\bar{y} \tag{13}$$</p>
<p>$$a = \frac{\sum_{i=0}^{t}{x_iy_i}-\bar{x}\bar{y}}{\sum_{i=0}^{t}{x_i^2 - \bar{x}^2}} \tag{14}$$</p>
<p>所以Eq(14)和Eq(9)就是最简单的最小二乘法的计算方法。</p>
<p>然后我们进一步考虑，如果输入和输出是多维数据，要如何计算。</p>
<p>假设输入信号为$X \in R^{m<em>t}$， 输出信号为$Y \in R^{n</em>t}$，那么有：</p>
<p>$$Y = W_0X+B = WX_1 \tag{15}$$</p>
<p>其中$W_0 \in R^{n<em>m}$是回归矩阵的系数，$B \in R^{1</em>t}$表示常数项，这里可以直接写到$W$矩阵中。$W \in R^{(m+1)*t}$，$X_1 \in R^{(m+1)*t}$<br>$$<br>X_1 = \begin{bmatrix}<br>x_{11} &amp;x_{12} &amp; … &amp;x_{1t}\<br>x_{11} &amp;x_{12} &amp; … &amp;x_{1t}\<br>{\vdots} &amp;{\vdots} &amp;… &amp;{\vdots}\<br>x_{m1} &amp;x_{m2} &amp;… &amp;x_{mt}\<br>1 &amp;1 &amp;… &amp;1\<br>\end{bmatrix} \tag{16}<br>$$</p>
<p>所以有：</p>
<p>$$\arg min_{W}({Y-WX_1}) \tag{17}$$</p>
<p>假设误差函数为$E$，则有：</p>
<p>$$E = (Y-WX_1)(Y-WX_1)^T = YY^T - WX_1Y^T-YX_1^TW^T+WX_1X_1^TW^T \tag{18}$$</p>
<p>计算$E$对$W$的偏导，则该偏导等于0：</p>
<p>$$\frac{\partial{E}}{\partial{W}} = -X_1Y^T-X_1^TY + 2WXX^T = 0 \tag{19}$$</p>
<p>所以有：</p>
<p>$$W = (X_1X_1^T)^{-1}X_1Y^T \tag{20}$$</p>
<p>至此矩阵形式的最小二乘法（多元线性回归的参数解法）推导完成。注意这里的$X_1$和$Y$中的数据排列方式为：每一行是一个维度的数据，每一列表示一个时间点。如果不是这么记录的话，那么公式需要加上转置。</p>
<p>后续会附上代码链接</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-04-13T09:32:08.000Z" title="2020/4/13 下午5:32:08">2020-04-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-13T01:03:01.891Z" title="2021/4/13 上午9:03:01">2021-04-13</time></span><span class="level-item"><a class="link-muted" href="/categories/Algorithm/">Algorithm</a></span><span class="level-item">8 minutes read (About 1236 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/13/Wiener-Filter/">Wiener-Filter</a></h1><div class="content"><h1 id="Wiener-Filter"><a href="#Wiener-Filter" class="headerlink" title="Wiener Filter"></a>Wiener Filter</h1><p>因为最近看文章接触了维纳滤波，所以这里写一下Weiner Filter的一些简单理解和推导。</p>
<h2 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h2><p>维纳滤波是一种在含噪声的时序信号把信号提取出来的滤波器，其基本框图如下：</p>
<p><img src="E:\GitHub-Blog\source\img\Wiener-Filter-1.jpg" alt="图-1：简单的Wiener-Filter"></p>
<p>简单的维纳滤波其实就是通过一个FIR滤波器，去除噪声的过程。在这里，$h$的作用也可以理解为： 通过训练集的数据对信号和噪声的建模，然后通过前几个点的信息，预测当前时刻的噪声信号所占的比例，然后去除掉，剩下的就是预测的时序信号了。维纳滤波作为一种使用很广泛的滤波器，其变化的形式也有很多种，可以是单输入输出的，也可以是多输入输出的。$h$所表示的变换也可以写成非线性；$h$可以是有限长的FIR滤波器，也可以是无限长的IIR滤波器。要取决于当前你所解决的问题。但是维纳滤波的基本思想还是一致的。通过滤波（矩阵或者其他模型的形式）来从信号和噪声的混合中提取信号。所以维纳滤波的核心，就是计算这个滤波器（矩阵$h$或者模型的参数）。也就是解Wiener-Hopf方程。</p>
<p>本文用比较简单的单输入输出，且只考虑有限长滤波（即认为当前时刻的信号只和前有限个时间点的信号相关）。</p>
<h2 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h2><p>首先，对于图1中的滤波器：</p>
<p>$$y(n) = x(n) * h(n) = (s(n)+v(n))*h(n) \tag{1}$$</p>
<p>其中$*$表示卷积，$x(n)$表示输入信号， $y(n)$表示输出信号， $s(n)$表示输入信号中，有用的信号部分；$v(n)$表示输入信号中的噪声部分。</p>
<p>维纳滤波的目标是，保证输出$y(n)$和真实信号$s(n)$的差别最小，由于$y(n)$和$s(n)$是时序信号，所以要保证两者的均方误差最小，所以有：</p>
<p>$$E{e^2(n)} = E{(y(n)-s(n))^2} = E{(x(n)*h(n)-s(n))^2} \tag{2} $$</p>
<p>即求使得Eq(2)最小的$h$。所以$E{e^2}$对$h$求偏导。有：</p>
<p>$$\frac{\partial{E{e^2(n)}}}{\partial{h}} = 2E{e(n) * \frac{\partial{e(n)}}{\partial{h}}} = 0 \tag{3} $$</p>
<p>$$\frac{\partial{E{e^2(n)}}}{\partial{h}} = 2E{[\sum_{m=0}^{N-1}{h(m)x(n-m) - s(n)}]x(n-j)}, j = 0, 1, … , N-1 \tag{4} $$</p>
<p>$$\frac{\partial{E{e^2(n)}}}{\partial{h}} = 2\sum_{m=1}^{N-1}{h(m)}E{x(n-j)x(n-m)} - 2E{s(n)x(n-j)} = 0, j = 0, 1, …, N-1 \tag{5} $$</p>
<p>我们设$x$和$s$的相关系数为$R_{xs}$，则有：</p>
<p>$$R_{xs}(j)=\sum_{m=0}^{N-1}{h(m)R_{xx}(j-m)}, j=0,1,…,N-1 \tag{6}$$</p>
<p>其中，$R_{xx}(j-m)$表示$x(n-j)$和$x(n-m)$的相关系数，这里$m$是固定的，$j$是变化的。且$m&gt;=0$，$R_{xs}(j)$表示$x(n-j)$和$s(n)$的相关系数。上述公式中，$n$表示的是时序信号中的时间点。</p>
<p>然后，根据Eq(6)，可以得到$N$个线性方程：<br>$$<br>\begin{cases}<br>R_{xs}(0)=h(0)R_{xx}(0)+h(1)R_{xx}(1)+…+h(N-1)R_{xx}(N-1)\<br>R_{xs}(1)=h(1)R_{xx}(1)+h(0)R_{xx}(0)+…+h(N-1)R_{xx}(N-2)\<br>…\<br>R_{xs}(N-1)=h(N-1)R_{xx}(N-1)+h(N-2)R_{xx}(N-2)+…+h(0)R_{xx}(0)\<br>\end{cases} \tag{7}<br>$$<br>写成矩阵形式，有：</p>
<p>$$\displaystyle \boldsymbol{R_{xx}H}=\boldsymbol{R_{xs}} \tag{8}$$</p>
<p>其中， $\displaystyle \boldsymbol{H} = [h(0), h(1),…,h(N-1)]^T$是需要求的滤波器参数</p>
<p>$$\displaystyle \boldsymbol{R_{xs}} = [R_{xs}(0),R_{xs}(1), …, R_{xs}(N-1)]^T$$是$x$和$s$的相关系数<br>$$<br>\displaystyle \boldsymbol{R_{xx}} = \begin{bmatrix}<br>R_{xx}(0)&amp;R_{xx}(1)&amp;…&amp;R_{xx}(N-1)\<br>R_{xx}(1)&amp;R_{xx}(0)&amp;…&amp;R_{xx}(N-2)\<br>{\vdots}&amp;{\vdots}&amp;…&amp;{\vdots}&amp;\<br>R_{xx}(N-1)&amp;R_{xx}(N-2)&amp;…&amp;R_{xx}(0)\<br>\end{bmatrix} \tag{9}<br>$$</p>
<p>所以根据Eq(8)可以求得：</p>
<p>$$\displaystyle \boldsymbol{H} = \boldsymbol{R_{xx}^{-1}R_{xs}} \tag{10}$$</p>
<p>此时，信号的均方误差最小，根据Eq(2)，可得：</p>
<p>$$E{e^2(n)} = E{(s(n)-\sum_{m=0}^{N-1}h(m)x(n-m))^2} \tag{11}$$</p>
<p>$$E{e^2(n)} = E{s^2(n) - 2s(n)\sum_{m=0}^{N-1}h(m)x(n-m)+\sum_{m=0}^{N-1}\sum_{r=0}^{N-1}{h(m)x(n-m)h(r)x(n-r)}}$$</p>
<p>$$E{e^2(n)}=R_{ss}(0)-2\sum_{m=0}^{N-1}{h(m)R_{xs}(m)+\sum_{m=0}^{N-1}{h(m)}\sum_{r=0}^{N-1}{h(r)R_{xx}(n-r)}}$$</p>
<p>根据Eq(5)，可得：</p>
<p>$$E{e^2(n)} = R_{ss}(0) - \sum_{m=0}^{N-1}{h(m)R_{xs}(n-m)} \tag{12}$$</p>
<p>假设信号$s(n)$和噪声$v(n)$互相独立，那么有：</p>
<p>$$R_{sv}= R_{vs} = 0$$</p>
<p>$$R_{xs} = R_{ss} + R_{vs} = R_{ss}$$</p>
<p>$$R_{xx} = R_{ss}+R_{sv}+R_{vs}+R_{vv} = R_{ss}+R_{vv}$$</p>
<p>则，根据Eq(12)，有：</p>
<p>$$E{e^2(n)} = R_{ss}(0) - \sum_{m=0}^{N-1}{h(m)R_{ss}(m)} \tag{14}$$</p>
<p>至此，最简单的维纳滤波的基本公式推导完成，如果涉及到多输入多输出的维纳滤波，会更加复杂，这里不做推导。后续会附上代码链接</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-03-20T07:00:48.000Z" title="2020/3/20 下午3:00:48">2020-03-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-03-24T02:46:16.000Z" title="2020/3/24 上午10:46:16">2020-03-24</time></span><span class="level-item"><a class="link-muted" href="/categories/coding/">coding</a></span><span class="level-item">11 minutes read (About 1659 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/03/20/python-note/">python_note</a></h1><div class="content"><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><h4 id="Basic-Knowledge"><a href="#Basic-Knowledge" class="headerlink" title="Basic Knowledge"></a>Basic Knowledge</h4><ol>
<li><p>python中新建一个变量并赋值，在计算机中是怎么处理的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>例如上述代码，计算机首先是开辟一块内存 ，如果是C++，Java等静态语言，那么会根据变量类型指定内存大小。如果是python等动态语言，则智能开辟内存大小，在内存中写入这一数据；但是计算机到目前为止，还不能将x和该值绑定，所以计算机中还会开辟一块内存，名字为x，然后将这一内存指向刚才开辟的内存地址。</p>
</li>
<li><p>python中没有指针的概念，例如下面的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">1</span></span><br><span class="line">y = x</span><br><span class="line">x = <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>在python中，这一过程是这样的：</p>
<ol>
<li>开辟内存，存入1，开辟内存，存入x，并将x指向刚才开辟的存入1的内存</li>
<li>开辟内存，存入y，并将y也指向x指向的那块内存</li>
<li>开辟内存，存入2，并将x指向新开的地址</li>
</ol>
<p>如果是在C++, Java等有指针概念的语言中，第二步应该是这样的，开辟新的内存，将x指向的地址的值复制一份存入新地址，开辟内存，存入y，并指向新地址</p>
</li>
<li><p>python循环</p>
<p>python中的循环有如下2种方式：</p>
<ol>
<li><p>for循环</p>
<p>python中的for循环的写法是for x in y, 也就是遍历数组y中的所有变量，提取出来的数是x，在数值计算中运用最多的是for x in range(1, 100), 这种方法是定义了一个1到100的数组，通过range函数，在内存中存储这样的数组，再遍历</p>
</li>
<li><p>while循环</p>
<p>这种方法和其他语言类似，不再赘述</p>
</li>
</ol>
</li>
<li><p>python函数</p>
<p>在python中，函数名是指向函数对象的一个引用，所以在python中，可以把函数名赋值给一个变量，这有点类似于matlab中的@func句柄的意思。</p>
<p>也就是说在python中，函数名对应的内存中，只存储了函数的名字以及队医你个Object的地址，所以可以幅值给另外一个变量。真正的函数对象是存储在另外的内存中的</p>
</li>
<li><p>函数的默认参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_end</span>(<span class="params">L=[]</span>):</span></span><br><span class="line">    L.append(<span class="string">&#x27;END&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> L</span><br></pre></td></tr></table></figure>

<p>这样一个函数，用默认参数调用一次，结果是[‘END’]，调用两次，结果是[‘END’, ‘END’]，这是因为，函数在运行时，默认参数也是存放在一块内存中的，每次调用时，由于内存 能够写入，所以每次运行完函数后，默认参数对应的内存都会刷新。所以python中，默认参数最好写成不变的量。</p>
</li>
<li><p>python迭代器</p>
<p>python中可以通过列表生成式的方式得到（类似于Matlab中的矩阵运算）。但是列表很大的时候，而且列表的数据很有规律（例如range(10000000)），但是又只需要用到列表中的少量数据，那么可以用迭代器(generator)的方法，描述列表的数字规律，当需要某个数时，根据规律计算得到，就不需要占用很大的内存了。</p>
</li>
<li><p>函数闭包(closure)</p>
<p>一个函数将另外一个函数作为返回值，并且在返回的函数中存储了内部的局部变量，这种方法称为闭包。闭包能保存原有的局部变量，在调用函数时引用，应用范围较广。但是闭包的应用中，要注意不能引用循环变量。因为闭包返回的函数是等所有函数都返回了才执行，而当所有函数都返回时，循环变量已经变为最终值。</p>
</li>
<li><p>偏函数</p>
<p>偏函数存在于functiontools中，主要的作用就是固定函数的某些参数，其返回值是一个函数。</p>
</li>
<li><p>线程锁</p>
<p>线程与进程的一个不同之处在于，进程之间的变量是独立的，如果两个进程同时读写某一内存，那么用Queue或者Pipe来保证读写的顺序。同时，进程只是把数据读取到自己的运算域内，相当于把数据拷贝一份。但是线程不一样，线程之间的变量是共享的，所以会导致线程对变量的赋值混乱。所以我们需要用线程锁。获得线程锁的线程，会保证在运行期间，变量只能由该线程修改。从而保证变量不会混乱。但是线程锁用完了一定要释放，最好用try…finally保证一定会释放。不然其他线程永远不能修改。但是线程锁也有缺陷，在一些并发线程中并不适用。</p>
</li>
<li><p>GIL锁</p>
<p>在Python的解释器中，有GIL(Global Interpreter Lock)。Python的线程在执行前，一定要获得GIL锁，然后一定时间后，解释器释放GIL锁，然后其他线程再获得GIL锁。这样会保证，同一个进程的多个线程，最多只能用到CPU的一个核。而不能跑满CPU。如果要充分利用CPU，那么可以用多进程的方式，或者用其他的语言实现，例如C，Java等。</p>
</li>
</ol>
<h4 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h4><ol>
<li><p>正则表达式的基本表达方式</p>
<table>
<thead>
<tr>
<th>标签</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>\d</td>
<td>匹配1个数字</td>
</tr>
<tr>
<td>\w</td>
<td>匹配1个字母或1个数字</td>
</tr>
<tr>
<td>.</td>
<td>可以匹配任何符号</td>
</tr>
<tr>
<td>×(star)</td>
<td>表示任意长度的字符</td>
</tr>
<tr>
<td>+</td>
<td>表示至少1个字符</td>
</tr>
<tr>
<td>?</td>
<td>表示0个或1个字符</td>
</tr>
<tr>
<td>{n}</td>
<td>表示n个字符</td>
</tr>
<tr>
<td>{n,m}</td>
<td>表示n-m个字符</td>
</tr>
<tr>
<td>\s</td>
<td>匹配一个空格</td>
</tr>
<tr>
<td>[]</td>
<td>用来表示范围</td>
</tr>
<tr>
<td>|</td>
<td>表示或</td>
</tr>
<tr>
<td>^</td>
<td>匹配一行的开头</td>
</tr>
<tr>
<td>$</td>
<td>匹配一行的结尾</td>
</tr>
<tr>
<td>()</td>
<td>表示分组</td>
</tr>
</tbody></table>
</li>
<li><p>正则表达式一般采用贪婪匹配，也就是说，如果前面的表达式符合要求，会一直匹配到不符合要求的那个数字，有可能导致后面的表达式匹配到空字符串。如果不想用贪婪匹配，那么需要在每一段表达式后面加上?。</p>
</li>
</ol>
<h4 id="难理解的点"><a href="#难理解的点" class="headerlink" title="难理解的点"></a>难理解的点</h4><ol>
<li>元类，metaclass</li>
<li>装饰器，decorator</li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-02-23T05:32:52.000Z" title="2020/2/23 下午1:32:52">2020-02-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-13T01:01:43.998Z" title="2021/4/13 上午9:01:43">2021-04-13</time></span><span class="level-item"><a class="link-muted" href="/categories/Mathematics/">Mathematics</a></span><span class="level-item">a few seconds read (About 56 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/02/23/Linear-Algebra/">Linear Algebra</a></h1><div class="content"><h2 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h2><p>本文主要记录学习过程中遇到的线性代数的基本概念以及公式</p>
<h3 id="Basic-Concept"><a href="#Basic-Concept" class="headerlink" title="Basic Concept"></a>Basic Concept</h3><h4 id="行列式的计算"><a href="#行列式的计算" class="headerlink" title="行列式的计算"></a>行列式的计算</h4><p>矩阵的行列式等于矩阵中任意一行的值</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-02-06T07:25:52.000Z" title="2020/2/6 下午3:25:52">2020-02-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-13T01:01:07.245Z" title="2021/4/13 上午9:01:07">2021-04-13</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a></span><span class="level-item">9 minutes read (About 1366 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/02/06/Gradient-Descent-Method/">Gradient Descent Method</a></h1><div class="content"><h4 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h4><p>这篇Blog的主要内容是关于梯度下降法的一些理解，以及相关的公式推导。梯度下降法很早之前就接触过，但是因为长时间不用，所以理解上也有了一些欠缺，今天看了一些参考文献，写一下自己的一些理解。便于以后帮助自己回忆。</p>
<h5 id="Artificial-Neural-Network"><a href="#Artificial-Neural-Network" class="headerlink" title="Artificial Neural Network"></a>Artificial Neural Network</h5><p>关于人工神经网络，这是目前使用最广泛的一类算法了。神经网络和其他的算法相比较，计算更加直接。不需要去推导公式，去计算两者的关系，直接通过网络的方式连接，然后用大量的数据训练，没有关系的连接权重逐渐变弱，有关系的权重逐渐变强。如果把输入和输出的函数关系写出来，会发现是一个很复杂的非线性公式。也正是因为这一点，神经网络的拟合程度比普通的线性，非线性算法都要好。</p>
<h5 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h5><p>对于用梯度下降法训练神经网络，我之前一直没有弄明白的点是<strong>为什么梯度的方向就是函数增加最快的方向</strong>， 我理解梯度方向是变化最快的方向，但是一直不理解为什么是增加的。今天看了一些参考文献，理解了一点。</p>
<p>对于神经网络，我们会有训练集的数据${x_0, y_0}$，$x$和$y$之间有函数关系$y = f(x)$，函数有自己的参数$p$，对应于神经网络的权值。所以有$y = f(p, x)$。为了能够训练神经网络，让输出和预期值越来越接近，可以定义损失函数(Loss Function)，有$l = L(x_0, y_0, y)$。其中$y = f(p, x_0)$，所以：</p>
<p>$$l = L(p, y_0, x_0)$$</p>
<p>计算$l$关于$p$的梯度，所以：</p>
<p>$$\bigtriangledown{C_{xr}(p)} = &lt; \frac{\partial{C_{xr}}}{\partial{p^{(0)}}}, …, \frac{\partial{C_{xr}}}{\partial{p^{(n)}}}$$</p>
<p><strong>沿梯度方向，损失函数$l$的值是逐渐增加的</strong></p>
<p>对这句话的理解，在于是什么量沿着梯度方向的变化。应该是自变量$p$。例如：</p>
<p>当$\frac{\partial{C_{xr}}}{\partial{p^{(0)}}}（p_0） &gt; 0$时，也就是说，函数$l(p^{0})$在$p_0$点时，函数曲线沿$p=p^0$的切线斜率是大于0的，也就是说，在很小的一个区间$(p_0-\delta, p_0+\delta)$，如果$p_1 &gt; p_0$， 那么有$l(p_1) &gt; l(p_0)$。所以，如果沿着梯度的负方向，损失函数的值也会降低。<strong>对于梯度大于0，会比较好理解，因为$l$是增函数</strong>。</p>
<p>如果$\frac{\partial{C_{xr}}}{\partial{p^{(0)}}}(p_0) &lt; 0$，那么有$l(p^0)$是减函数，也就是说，函数在$p_0$点沿$p = p^0$的切线斜率是小于0的。即，在很小的一个区间$(p_0-\delta, p_0+\delta)$，如果$p_1 &gt; p_0$， 那么有$l(p_1) &lt; l(p_0)$。但是由于梯度本身小于0，所以梯度的反方向就是$p^0$递增的方向。又因为$l(p^0)$是减函数，所以沿梯度的负方向，$l(p^0)$还是会逐渐降低。</p>
<h4 id="Neural-Network中梯度下降法的推导"><a href="#Neural-Network中梯度下降法的推导" class="headerlink" title="Neural Network中梯度下降法的推导"></a>Neural Network中梯度下降法的推导</h4><p>这里用最简单的全连接网络为例，如图所示：</p>
<p><img src="/img/Gradient-Descent-1.png" alt="全连接网络"></p>
<p>$x$：网络的输入值</p>
<p>$w_1, w_2, w_3$：层与层的连接参数</p>
<p>$h_1, h_2$：中间层的输入值</p>
<p>$o_1,o_2$：中间层的输出值</p>
<p>$y$：网络的输出值</p>
<p>假设输入参数的个数为$m$，输出参数的个数为$n$，第一层的神经元个数为$a$，第二层的神经元参数为$b$，所以：</p>
<p>$x \in R^{1*m}$</p>
<p>$y \in R^{1*n}$</p>
<p>$h_1, o_1 \in R^{1*a}$</p>
<p>$h_2, o_2 \in R^{1*b}$</p>
<p>$w_1 \in R^{m*a}$</p>
<p>$w_2 \in R^{a*b}$</p>
<p>$w_3 \in R^{b*n}$</p>
<p>网络中每层的激活函数(activation function)用sigmoid函数：</p>
<p>$f(x) = \frac{1}{1+e^{-x}}$</p>
<p>sigmoid函数的导数有如下特点(可以自己推导)：</p>
<p>$f’(x) = f(x)*(1-f(x))$</p>
<p>假设用来训练的数据集为$&lt;x, r&gt;$，$x$为输入值，$r$为输出值</p>
<p>损失函数为：</p>
<p>$L = \frac{1}{2}*(y-r)^{2}$</p>
<p>所以有如下公式：</p>
<p>$$h_1=w_1*x+b_1$$</p>
<p>$$o_1=sigmoid(h_1)$$</p>
<p>$$h_2=w_2*o_1+b_2$$</p>
<p>$$o_2=sigmoid(h_2)$$</p>
<p>$$h_3=w_3*o_2+b_3$$</p>
<p>$$y=sigmoid(h_3)$$</p>
<p>计算$L$关于$w_3$的梯度，有：</p>
<p>$$\frac{\partial{L}}{\partial{w_3}}=(y-r)*\frac{\partial{(y-r)}}{\partial{w_3}}$$</p>
<p>$$=(y-r)*\frac{\partial{(y-r)}}{\partial{h_3}}*\frac{\partial{h_3}}{\partial{w_3}}$$</p>
<p>$$= (y-r)<em>(y-r)</em>[1- (y-r)]*o_2$$</p>
<p>$$= (y-r)^{2} * (1-y+r) * o_2$$</p>
<p>类似的，可以得到：</p>
<p>$$\frac{\partial{L}}{\partial{b_3}}=(y-r)^{2}*(1-y+r)$$</p>
<p>$$\frac{\partial{L}}{\partial{w_2}}=(y-r)^{2} * (1-y+r) * w_3 * o_2 * (1-o_2) * o_1$$</p>
<p>$$\frac{\partial{L}}{\partial{b_2}}=(y-r)^{2} * (1-y+r) * w_3 * o_2 * (1-o_2)$$</p>
<p>$$\frac{\partial{L}}{\partial{w_1}}=(y-r)^{2} * (1-y+r) * w_3 * o_2 * (1-o_2) * o_1 * (1-o_1) * x$$</p>
<p>$$\frac{\partial{L}}{\partial{b_1}}=(y-r)^{2} * (1-y+r) * w_3 * o_2 * (1-o_2) * o_1 * (1-o_1)$$</p>
<p>计算损失函数$L$关于网络权重的梯度后，网络权重的变化为：</p>
<p>$$\bigtriangleup W = - \eta * \frac{\partial{L}}{\partial{W}}$$</p>
<p>其中， $W$是网络中的权重参数，一般只通过学习率来调节网络训练的快慢，是不够的。会加入动态变化量，以加快学习过程。所以：</p>
<p>$$\bigtriangleup W=-\eta * \frac{\partial{L}}{\partial{W}} + \alpha * \frac{\partial{L}}{\partial{W}}$$</p>
<p>其中，$\alpha$表示动态变化项，是一个常数。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-02-01T11:50:30.000Z" title="2020/2/1 下午7:50:30">2020-02-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-02-01T11:50:30.000Z" title="2020/2/1 下午7:50:30">2020-02-01</time></span><span class="level-item">a minute read (About 139 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/02/01/hello-world/">Hello World</a></h1><div class="content"><p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><h3 id="生成静态文件"><a href="#生成静态文件" class="headerlink" title="生成静态文件"></a>生成静态文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><h3 id="将生成的文件部署到github"><a href="#将生成的文件部署到github" class="headerlink" title="将生成的文件部署到github"></a>将生成的文件部署到github</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-01-21T06:11:55.000Z" title="2020/1/21 下午2:11:55">2020-01-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-13T00:59:56.263Z" title="2021/4/13 上午8:59:56">2021-04-13</time></span><span class="level-item"><a class="link-muted" href="/categories/Lecture/">Lecture</a></span><span class="level-item">3 minutes read (About 415 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/01/21/Brain-Structure-Conference/">Brain Structure Conference</a></h1><div class="content"><h3 id="介观脑连接研讨会"><a href="#介观脑连接研讨会" class="headerlink" title="介观脑连接研讨会"></a>介观脑连接研讨会</h3><p><img src="/img/Brain-Structure-Conference-1.jpg" alt="open scence"></p>
<h4 id="Focused-Questions"><a href="#Focused-Questions" class="headerlink" title="Focused Questions"></a>Focused Questions</h4><ul>
<li>大脑神经回路与功能的关系</li>
<li>大脑神经连接的建模与计算</li>
</ul>
<h4 id="Muming-Poo"><a href="#Muming-Poo" class="headerlink" title="Muming Poo"></a>Muming Poo</h4><p><img src="/img/Brain-Structure-Conference-2.jpg" alt="neural types and mappings"></p>
<ul>
<li>mapping and understanding </li>
<li>genetic programs and neural circuits, subtypes and substates</li>
</ul>
<p><img src="/img/Brain-Structure-Conference-3.jpg" alt="Float Chat of Primate Brain Research"></p>
<ul>
<li>Jun Yan<ul>
<li>single neuron projectome</li>
<li>projection subtypes, CT</li>
<li>brain  orders and projectome classification, 观察轴突分叉点的夹角</li>
</ul>
</li>
</ul>
<h4 id="Florian-Engert"><a href="#Florian-Engert" class="headerlink" title="Florian Engert"></a>Florian Engert</h4><ul>
<li>不同类型的神经元组成不同的神经回路，回路之间互相影响，各有各的作用。</li>
</ul>
<h4 id="JiuLin-Du"><a href="#JiuLin-Du" class="headerlink" title="JiuLin Du"></a>JiuLin Du</h4><ul>
<li>神经元分类， vglut2a, vglut2b(excitory), GABA(jinhibotiry)等<ul>
<li>神经信号的传递有兴奋和抑制之分，不同的神经递质对应了不同的神经信号的gate</li>
</ul>
</li>
<li>gene expression</li>
<li>信息传导通路</li>
</ul>
<h4 id="Hongkui-Zheng"><a href="#Hongkui-Zheng" class="headerlink" title="Hongkui Zheng"></a>Hongkui Zheng</h4><p><img src="/img/Brain-Structure-Conference-4.jpg" alt="Multi-level decoding of neuron"></p>
<ul>
<li>multi-level approach to decoding the brain</li>
<li>cell types, connectivity, psyology and behavior, modeling and thery</li>
<li>层层递进的网络结构设计</li>
<li>细胞类型的定义，基于细胞类型定义的回路功能研究（<em>对网络结构设计具有一定的参考意义</em>）</li>
<li>feedforward and feedback pathway（前向神经网络和反馈式神经网络）</li>
<li>corticalcortical, thalamocoritcal and corticalthalamic projection matrices(Harris, Nature, 2019)</li>
<li>sparse labeling（稀疏标签）</li>
<li>shared types of neurons in different cortical areas</li>
</ul>
<p><img src="/img/Brain-Structure-Conference-5.jpg" alt="summary"></p>
<h4 id="Chenyu-Li"><a href="#Chenyu-Li" class="headerlink" title="Chenyu Li"></a>Chenyu Li</h4><ul>
<li>causal map, behavior,<ul>
<li>memory in the brain</li>
</ul>
</li>
<li>connectome without function is meanless</li>
</ul>
<h4 id="Linda-Richard"><a href="#Linda-Richard" class="headerlink" title="Linda Richard"></a>Linda Richard</h4><ul>
<li></li>
</ul>
<h4 id="Dan-Yang"><a href="#Dan-Yang" class="headerlink" title="Dan Yang"></a>Dan Yang</h4><p><img src="/img/Brain-Structure-Conference-6.jpg" alt="sleep active neurons"></p>
<ul>
<li></li>
</ul>
<h4 id="David-Van-Essen"><a href="#David-Van-Essen" class="headerlink" title="David Van Essen"></a>David Van Essen</h4><ul>
<li>resting-state networks</li>
</ul>
<h4 id="XiaoJing-Wang"><a href="#XiaoJing-Wang" class="headerlink" title="XiaoJing Wang"></a>XiaoJing Wang</h4><p><img src="/img/Brain-Structure-Conference-7.jpg" alt="connectome"></p>
<ul>
<li>Theoretical Neuroscience Rising </li>
<li>Computational and Congnitive Neuroscience(CCN)</li>
<li>generative and connectivity</li>
<li>connectivity is insufficient to predict dynamics</li>
</ul>
<p><img src="/img/Brain-Structure-Conference-8.jpg" alt="conectivity is insufficient to predict dynamics"></p>
<h4 id="Helen-Barbas"><a href="#Helen-Barbas" class="headerlink" title="Helen Barbas"></a>Helen Barbas</h4><ul>
<li></li>
</ul>
<h4 id="Anthony-Movshon"><a href="#Anthony-Movshon" class="headerlink" title="Anthony Movshon"></a>Anthony Movshon</h4><p><img src="/img/Brain-Structure-Conference-9.jpg" alt="levels of invistigation"></p>
<ul>
<li>brain models and simulation</li>
<li>mainflold</li>
</ul>
<p><img src="/img/Brain-Structure-Conference-10.jpg" alt="Human Brain Project"></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/portrait.jpg" alt="Frank Wan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Frank Wan</p><p class="is-size-6 is-block">Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hangzhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">19</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">18</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/FrankMartinem" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/FrankMartinem"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:frankmartinet@163.com"><i class="fa fa-envelope"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zju.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ZJU</span></span><span class="level-right"><span class="level-item tag">www.zju.edu.cn</span></span></a></li><li><a class="level is-mobile" href="https://www.hust.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">HUST</span></span><span class="level-right"><span class="level-item tag">www.hust.edu.cn</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Lecture/"><span class="level-start"><span class="level-item">Lecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Mathematics/"><span class="level-start"><span class="level-item">Mathematics</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/coding/"><span class="level-start"><span class="level-item">coding</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-28T08:50:27.000Z">2021-05-28</time></p><p class="title"><a href="/2021/05/28/Optimal-Linear-Estimation/">Optimal Linear Estimation</a></p><p class="categories"><a href="/categories/Algorithm/">Algorithm</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-03T10:29:42.000Z">2021-05-03</time></p><p class="title"><a href="/2021/05/03/ZJU%20RVPN%20Initialize%20Failed/">ZJU RVPN initialize failed</a></p><p class="categories"><a href="/categories/software/">software</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-05-16T09:01:22.000Z">2020-05-16</time></p><p class="title"><a href="/2020/05/16/Berkeley-CS-61A/">Berkeley-CS-61A</a></p><p class="categories"><a href="/categories/Lecture/">Lecture</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-04-16T17:09:41.000Z">2020-04-17</time></p><p class="title"><a href="/2020/04/17/Linear-Square-Method/">Linear Square Method</a></p><p class="categories"><a href="/categories/Algorithm/">Algorithm</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-04-13T09:32:08.000Z">2020-04-13</time></p><p class="title"><a href="/2020/04/13/Wiener-Filter/">Wiener-Filter</a></p><p class="categories"><a href="/categories/Algorithm/">Algorithm</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/03/"><span class="level-start"><span class="level-item">March 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">February 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/01/"><span class="level-start"><span class="level-item">January 2020</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">November 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C#</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Science/"><span class="tag">Computer Science</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gradient-Descent/"><span class="tag">Gradient Descent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hidden-Markov-Model/"><span class="tag">Hidden Markov Model</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kalman/"><span class="tag">Kalman</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lecture/"><span class="tag">Lecture</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Algebra/"><span class="tag">Linear Algebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Regression/"><span class="tag">Linear Regression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Optimal-Linear-Estimation/"><span class="tag">Optimal Linear Estimation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PCA/"><span class="tag">PCA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PVA/"><span class="tag">PVA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Statistics/"><span class="tag">Statistics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unscented-Kalman-Filter/"><span class="tag">Unscented Kalman Filter</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wiener-Filter/"><span class="tag">Wiener Filter</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/software-usage/"><span class="tag">software usage</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="FrankMartinem Blog" height="28"></a><p class="is-size-7"><span>&copy; 2021 Frank</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>